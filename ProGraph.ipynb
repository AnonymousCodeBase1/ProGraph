{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data(object):\n",
    "    def __init__(self):\n",
    "        self.IP = []\n",
    "        self.cert = []\n",
    "        self.urls = []\n",
    "        self.static_features = []\n",
    "        self.seq = []\n",
    "        self.label = []\n",
    "        self.time = []\n",
    "        self.image = []\n",
    "        self.fn = []\n",
    "        \n",
    "    def insert(self,IP,cert,urls,static_features,seq,label,time,image,fn):\n",
    "        self.IP.append(IP)\n",
    "        self.cert.append(cert)\n",
    "        self.urls.append(urls)\n",
    "        self.static_features.append(static_features)\n",
    "        self.seq.append(seq)\n",
    "        self.label.append(label)\n",
    "        self.time.append(time)\n",
    "        self.image.append(image)\n",
    "        self.fn.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval import Interval\n",
    "import os,shutil\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "class cert_cluster(object):\n",
    "    def __init__(self):\n",
    "        self.IPs = []\n",
    "        self.urls = {} #{urls:number}\n",
    "        self.url_number = [] # sorted (url:number)\n",
    "        self.url_weight = {}#{url:weight}\n",
    "        self.url_unique = []\n",
    "        self.certs = [] \n",
    "        self.sessions = []\n",
    "        self.images = []\n",
    "        self.static_features = []\n",
    "        self.fn = []\n",
    "        \n",
    "\n",
    "        self.seq = []\n",
    "        self.label = -1\n",
    "        self.tag = -1\n",
    "        self.time_slides = [] #(start,end)\n",
    "        \n",
    "        self.sim_list = []\n",
    "        self.url_all = []\n",
    "        \n",
    "        self.ip_weight = {}\n",
    "        self.cert_weight = {}\n",
    "        \n",
    "    #file name\n",
    "    def fn_cal(self):\n",
    "        self.fn = [ss['fn'] for ss in self.sessions]\n",
    "            \n",
    "        \n",
    "    #all urls\n",
    "    def all_url_cal(self):\n",
    "        for session in self.sessions:\n",
    "            urls = session['urls']\n",
    "            for url in urls:\n",
    "                if url not in self.url_all:\n",
    "                    self.url_all.append(url)\n",
    "    #url sim cal\n",
    "    def sim_cal(self,urls_dict):\n",
    "        self.sim_list = []\n",
    "        for url_dict_per in urls_dict:\n",
    "            score = 0\n",
    "            for url in self.url_unique:\n",
    "                if url in url_dict_per:\n",
    "                    score += 1\n",
    "            self.sim_list.append(score / (len(self.url_unique)*1.0))\n",
    "        if np.array(self.sim_list).max() > 0:\n",
    "            self.sim_list = self.sim_list/np.array(self.sim_list).max()\n",
    "        max_idx = np.argmax(np.array(self.sim_list))\n",
    "        for i in range(len(self.sim_list)):\n",
    "            if i!=max_idx:\n",
    "                self.sim_list[i] = 0\n",
    "            \n",
    "    #ip sim cal\n",
    "    def sim_ip_cal(self,urls_dict):\n",
    "        self.sim_list = []\n",
    "        for url_dict_per in urls_dict:\n",
    "            score = 0\n",
    "            for url in self.IPs:\n",
    "                if url in url_dict_per:\n",
    "                    score += 1\n",
    "            self.sim_list.append(score)\n",
    "        if np.array(self.sim_list).max() > 0:\n",
    "            self.sim_list = self.sim_list/np.array(self.sim_list).max()\n",
    "        max_idx = np.argmax(np.array(self.sim_list))\n",
    "        for i in range(len(self.sim_list)):\n",
    "            if i!=max_idx:\n",
    "                self.sim_list[i] = 0\n",
    "        \n",
    "            \n",
    "    \n",
    "    #static\n",
    "    def static_cal(self):\n",
    "        self.static_features = [a['static_features'] for a in self.sessions]\n",
    "    \n",
    "    \n",
    "    #major voting for cluster's label\n",
    "    def label_cal(self):\n",
    "        labels = [a['label'] for a in self.sessions]\n",
    "        self.label = max(labels,key = labels.count)\n",
    "        \n",
    "    def tag_cal(self):\n",
    "        tags = [a['tag'] for a in self.sessions]\n",
    "        self.tag = max(tags,key = tags.count)\n",
    "    \n",
    "    #image extract\n",
    "    def image_cal(self):\n",
    "        self.images = [item['image'].flatten() for item in self.sessions]\n",
    "    \n",
    "    #seq_ipdaate\n",
    "    def seq_cal(self):\n",
    "#         self.seq = [item['seq'].flatten() for item in self.sessions]\n",
    "        for i in range(len(self.sessions)):\n",
    "            session = self.sessions[i]\n",
    "            mat = session['seq']\n",
    "            sta = session['static_features']\n",
    "            for item in sta:\n",
    "                mat = np.append(mat,float(item))\n",
    "\n",
    "            self.seq.append(mat)\n",
    "            \n",
    "            \n",
    "        \n",
    "    #time_slieds generation\n",
    "    def time_cal(self):\n",
    "        def getfirst(item):\n",
    "            return item[0]\n",
    "        for session in self.sessions:\n",
    "            self.time_slides.append(session['time'])\n",
    "#         print(self.time_slides)\n",
    "        self.time_slides = sorted(self.time_slides,key=getfirst)\n",
    "        \n",
    "        #concat time period\n",
    "        self.time_slides = [Interval(item[0],item[1],lower_closed=True, upper_closed=True) for item in self.time_slides]\n",
    "#         print(len(self.time_slides))\n",
    "        while True:\n",
    "            big_flag = 0\n",
    "            for i in range(len(self.time_slides)):\n",
    "                \n",
    "                flag = 0\n",
    "                for j in range(len(self.time_slides)):\n",
    "#                     print((i,j))\n",
    "                    if i ==len(self.time_slides)-1 and j == len(self.time_slides)-1:\n",
    "                        big_flag =1\n",
    "                    if i==j:\n",
    "                        continue      \n",
    "                    if self.time_slides[i].overlaps(self.time_slides[j]):\n",
    "                        interval_merge = self.time_slides[i].join(self.time_slides[j])\n",
    "                        self.time_slides[i] = interval_merge\n",
    "                        del self.time_slides[j]\n",
    "\n",
    "                        flag = 1\n",
    "                        break                \n",
    "                if flag == 1:\n",
    "                    break\n",
    "            if big_flag==1:\n",
    "                break\n",
    "        self.time_slides = [(item.lower_bound,item.upper_bound) for item in self.time_slides]\n",
    "#         print(self.time_slides)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                \n",
    "    def urls_cal(self):\n",
    "        for item in self.sessions:\n",
    "            urls = item['urls']\n",
    "            for url in urls:\n",
    "                if url not in list(self.urls.keys()):\n",
    "                    self.urls[url] = 1\n",
    "                else:\n",
    "                    self.urls[url] += 1\n",
    "        #sorted\n",
    "        self.url_number = sorted(self.urls.items(),key=lambda item:item[1],reverse=True)\n",
    "    \n",
    "\n",
    "    def urls_weight(self):\n",
    "        total = np.array([item[1] for item in self.url_number]).sum()*1.0\n",
    "        for item in self.url_number:\n",
    "            self.url_weight[item[0]] = item[1]*1.0/total\n",
    "                \n",
    "#         self.url_weight = [(item[0],item[1]*1.0/total) for item in self.url_number]\n",
    "        self.url_unique = [item[0] for item in self.url_number]\n",
    "        \n",
    "\n",
    "    def ips_cal(self):\n",
    "        for item in self.sessions:\n",
    "            if item['IP'] not in self.IPs:\n",
    "                self.IPs.append(item['IP'])\n",
    "    \n",
    "\n",
    "    def cert_cal(self):\n",
    "        for item in self.sessions:\n",
    "            if item['cert'] not in self.certs:\n",
    "                self.certs.append(item['cert'])\n",
    "        self.certs = [item for item in self.certs if item is not 0]\n",
    "    \n",
    "\n",
    "    def url_clean(self):\n",
    "        if len(self.url_number) <=5:\n",
    "            return\n",
    "        self.url_number = self.url_number[:5]\n",
    "        self.url_unique = [item[0] for item in self.url_number]\n",
    "        self.url_weight = {}\n",
    "        self.urls_weight()\n",
    "        \n",
    "    #ip_weigth\n",
    "    def ip_weight_cal(self):\n",
    "        self.ip_weight = {}\n",
    "        for session in self.sessions:\n",
    "            if session['IP'] not in list(self.ip_weight.keys()):\n",
    "                self.ip_weight[session['IP']] = 1.0/(len(self.sessions)*1.0)\n",
    "            else:\n",
    "                self.ip_weight[session['IP']] += 1.0/(len(self.sessions)*1.0)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    #cert_weigth\n",
    "    def cert_weight_cal(self):\n",
    "        self.cert_weight = {}\n",
    "        count = 0\n",
    "        for session in self.sessions:\n",
    "            if session['cert'] != 0 and session['cert'] not in list(self.cert_weight.keys()):\n",
    "                self.cert_weight[session['cert']] = 1\n",
    "                count +=1\n",
    "            elif session['cert'] != 0 and session['cert'] in list(self.cert_weight.keys()):\n",
    "                self.cert_weight[session['cert']] += 1\n",
    "                count +=1\n",
    "        if count != 0:\n",
    "            for key in list(self.cert_weight.keys()):\n",
    "                self.cert_weight[key] = self.cert_weight[key]/(count*1.0)\n",
    "    \n",
    "    \n",
    "    #更新cert_clt\n",
    "    def update(self):\n",
    "        self.urls_cal()\n",
    "        self.urls_weight()\n",
    "        self.ips_cal()\n",
    "        self.cert_cal()\n",
    "        self.seq_cal()\n",
    "        self.image_cal()\n",
    "        self.label_cal()\n",
    "        self.tag_cal()\n",
    "        self.static_cal()\n",
    "        self.url_clean()\n",
    "        self.all_url_cal()\n",
    "        self.fn_cal()\n",
    "        \n",
    "        self.cert_weight_cal()\n",
    "        self.ip_weight_cal()\n",
    "        \n",
    "#         self.time_cal()\n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_matrix_gen(clusters):\n",
    "    def cert_sim(clt1,clt2):\n",
    "        if len(list(clt1.cert_weight.keys())) == 0 or len(list(clt2.cert_weight.keys())) == 0:\n",
    "            return 0\n",
    "        cross_keys = list(set(list(clt1.cert_weight.keys()))&set(list(clt2.cert_weight.keys())))\n",
    "        score = 0.0\n",
    "        for key in cross_keys:\n",
    "            score += clt1.cert_weight[key]*clt2.cert_weight[key]\n",
    "        return score\n",
    "    def ip_sim(clt1,clt2):\n",
    "        if len(list(clt1.ip_weight.keys())) == 0 or len(list(clt2.ip_weight.keys())) == 0:\n",
    "            return 0\n",
    "        cross_keys = list(set(list(clt1.ip_weight.keys()))&set(list(clt2.ip_weight.keys())))\n",
    "        score = 0.0\n",
    "        for key in cross_keys:\n",
    "            score += clt1.ip_weight[key]*clt2.ip_weight[key]\n",
    "        return score\n",
    "    \n",
    "    def url_sim(clt1,clt2):\n",
    "        if len(clt1.url_unique) == 0 or len(clt2.url_unique) == 0:\n",
    "            return 0\n",
    "        \n",
    "        overlaps = list(set(clt1.url_unique)&set(clt2.url_unique))\n",
    "        if len(overlaps) is 0:\n",
    "            return 0\n",
    "        res =  np.array([clt1.url_weight[key]*clt2.url_weight[key] for key in overlaps]).sum() / len(overlaps)\n",
    "#         print(res)\n",
    "        if res <0.3:\n",
    "            res = 0\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def time_sim(clt1,clt2):\n",
    "        clt1_time = [Interval(item[0],item[1],lower_closed=True, upper_closed=True) for item in clt1.time_slides]\n",
    "        clt2_time = [Interval(item[0],item[1],lower_closed=True, upper_closed=True) for item in clt2.time_slides]\n",
    "        count = 0\n",
    "        for clt1_t in clt1_time:\n",
    "            for clt2_t in clt2_time:\n",
    "                if clt1_t.overlaps(clt2_t):\n",
    "                    count+=1\n",
    "        if count <=7:\n",
    "            count = 0\n",
    "        return count\n",
    "    \n",
    "    mat = np.zeros((len(clusters),len(clusters)))\n",
    "    for i in range(len(clusters)):\n",
    "        for j in range(i,len(clusters)):\n",
    "            if i==j:\n",
    "                continue\n",
    "            mat[i][j] = url_sim(clusters[i],clusters[j]) + cert_sim(clusters[i],clusters[j]) + ip_sim(clusters[i],clusters[j]) #+ time_sim(clusters[i],clusters[j])\n",
    "            if i!=j:\n",
    "                mat[j][i] = mat[i][j]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clt_analysis(clts, adj_matrix):\n",
    "    inter_per_list = []\n",
    "    max_indx_list = []\n",
    "    outer_score_list_all = []\n",
    "    for i in range(adj_matrix.shape[0]):\n",
    "        if clts[i].tag == 0:\n",
    "            continue\n",
    "        inter_score = 0.0\n",
    "        outer_score = 0.0\n",
    "#         inter_score_list = [0.0 for i in range(10)]\n",
    "        outer_score_list = [0.0 for i in range(10)]\n",
    "        \n",
    "        for j in range(adj_matrix.shape[0]):\n",
    "            if i==j or clts[j].tag == 0:\n",
    "                continue\n",
    "            if clts[i].label == clts[j].label:\n",
    "                inter_score += adj_matrix[i][j]\n",
    "                outer_score_list[int(clts[i].label)] += adj_matrix[i][j]\n",
    "            else:\n",
    "                outer_score_list[int(clts[j].label)] += adj_matrix[i][j]\n",
    "                outer_score += adj_matrix[i][j]\n",
    "        if (inter_score+outer_score) != 0:\n",
    "            inter_per_list.append(inter_score/(inter_score+outer_score))\n",
    "        else:\n",
    "            inter_per_list.append(-1)\n",
    "            \n",
    "#         outer_score_list[clts[i].label] = adj_matrix[i][i]\n",
    "        max_indx_list.append(np.argmax(np.array(outer_score_list)))\n",
    "        outer_score_list_all.append(outer_score_list)\n",
    "    outer_clt = []\n",
    "    for i in range(len(inter_per_list)):\n",
    "        if inter_per_list[i] <=0.5 and inter_per_list[i] >= 0:\n",
    "            outer_clt.append((i,clts[i]))\n",
    "    max_indx_list = [(outer_score_list_all[i][clts[i].label],outer_score_list_all[i], len(clts[i].sessions)) for i in range(len(max_indx_list)) if max_indx_list[i] != int(clts[i].label) and np.array(max_indx_list[i]).sum()>0]\n",
    "    return outer_clt,max_indx_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhc_iso(clts,labels):\n",
    "    def time_sim(clt1,clt2):\n",
    "        clt1_time = [Interval(item[0],item[1],lower_closed=True, upper_closed=True) for item in clt1.time_slides]\n",
    "        clt2_time = [Interval(item[0],item[1],lower_closed=True, upper_closed=True) for item in clt2.time_slides]\n",
    "        count = 0\n",
    "        for clt1_t in clt1_time:\n",
    "            for clt2_t in clt2_time:\n",
    "                if clt1_t.overlaps(clt2_t):\n",
    "                    count+=1\n",
    "        return count\n",
    "    \n",
    "    #deal with the isolated clts only\n",
    "    zero_idx = [i for i in range(len(labels)) if labels[i] == -1]\n",
    "    \n",
    "    for idx in zero_idx:\n",
    "        #for each clt, we calculate the time sim with other clts\n",
    "        score_list = [0.0 for x in range(10)]\n",
    "        for j in range(len(clts)):\n",
    "            if j == idx:\n",
    "                continue\n",
    "            score = time_sim(clts[idx],clts[j])\n",
    "            score_list[labels[j]] += score\n",
    "        pred_label = np.argmax(np.array(score_list))\n",
    "        labels[idx] = pred_label\n",
    "        \n",
    "    return labels\n",
    "        \n",
    "def check_zero_label(adj_matrix,labels):\n",
    "    idxs = []\n",
    "    for i in range(adj_matrix.shape[0]):\n",
    "        if labels[i] == -1:\n",
    "            continue\n",
    "        flag = 1\n",
    "        count = 0\n",
    "        for j in range(adj_matrix.shape[0]):\n",
    "            if i==j:\n",
    "                continue\n",
    "            if labels[j] == -1:\n",
    "                continue\n",
    "            if labels[i] == labels[j] and adj_matrix[i][j] != 0:\n",
    "                flag = 0\n",
    "            elif labels[i] != labels[j] and adj_matrix[i][j] != 0:\n",
    "                count += adj_matrix[i][j]\n",
    "        if flag and count != 0:\n",
    "            idxs.append(i)\n",
    "    return idxs\n",
    "            \n",
    "def zero_adj(zero_idxs,clts, adj_matrix):\n",
    "    for idx in zero_idxs:\n",
    "        if clts[idx].tag == 0:\n",
    "            continue\n",
    "        cand = clts[idx]\n",
    "        score_list = [0.0 for i in range(10)]\n",
    "        for i in range(len(clts)):\n",
    "            if i==idx:\n",
    "                continue\n",
    "            score_list[clts[i].label] += adj_matrix[idx][i]\n",
    "        prob = np.array(softmax(score_list))\n",
    "        if np.argmax(prob) != clts[idx].label and prob[np.argmax(prob)] >= 0.9:\n",
    "            clts[idx].label = np.argmax(prob)\n",
    "    return clts\n",
    "        \n",
    "\n",
    "def check_zero(adj_matrix):\n",
    "    sum_v = np.sum(adj_matrix,axis=0).reshape((adj_matrix.shape[0],1)) - np.array([adj_matrix[i][i] for i in range(adj_matrix.shape[0])]).reshape((adj_matrix.shape[0],1))\n",
    "    zero_idx = [i for i in range(sum_v.shape[0]) if int(sum_v[i]) == 0]\n",
    "    print(len(zero_idx))\n",
    "    return zero_idx\n",
    "\n",
    "#adjust the label of outer clts\n",
    "def clt_adj(clts,o_clts):\n",
    "    def cert_sim(clt1,clt2):\n",
    "        if len(clt1.certs) == 0 or len(clt2.certs) == 0:\n",
    "            return 0\n",
    "        return len(list(set(clt1.certs)&set(clt2.certs)))\n",
    "    def ip_sim(clt1,clt2):\n",
    "        return len(list(set(clt1.IPs)&set(clt2.IPs)))\n",
    "    for o_idx,o_clt in o_clts:\n",
    "        clss = [0.0 for i in range(10)]\n",
    "        for i in range(len(clts)):\n",
    "            if i==o_idx:\n",
    "                continue\n",
    "            sim = cert_sim(o_clt,clts[i]) + ip_sim(o_clt,clts[i])\n",
    "            clss[clts[i].label] += sim\n",
    "        if np.array(clss).max() < 2:\n",
    "            print(\"{} no need for adjustment\".format(o_idx))\n",
    "            continue\n",
    "        if np.argmax(np.array(clss)) != o_clt.label:\n",
    "            print(\"{}: {} -> {}\".format(o_idx, o_clt.label,np.argmax(np.array(clss))))\n",
    "            clts[o_idx].label = np.argmax(np.array(clss))\n",
    "                           \n",
    "    return clts\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x - np.max(x))/(np.sum(np.exp(x - np.max(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "\n",
    "def spread(clts,adj_matrix,labels):\n",
    "    #predict the unlabel clts\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != -1:\n",
    "            continue\n",
    "        score_list = [0.0 for x in range(10)]\n",
    "        for j in range(len(labels)):\n",
    "            if i==j: #ignore the self-node\n",
    "                continue\n",
    "            if labels[j] == -1: #ignore the unlabel testing nodes\n",
    "                continue\n",
    "            score_list[labels[j]] += adj_matrix[i][j]\n",
    "        if np.array(score_list).sum() == 0:\n",
    "            continue\n",
    "        score_list = np.array(softmax(score_list))\n",
    "        pred_label = np.argmax(score_list)\n",
    "        #tag the predicted label\n",
    "        labels[i] = pred_label\n",
    "#         print(pred_label)\n",
    "    return labels\n",
    "\n",
    "def acc_per_round(clts,labels):\n",
    "    gt_labels = [clt.label for clt in clts]\n",
    "    acc = accuracy_score(gt_labels,labels)\n",
    "    pre = recall_score(gt_labels,labels,average=\"weighted\")\n",
    "    rec = precision_score(gt_labels,labels, average=\"weighted\")\n",
    "    f1 = f1_score(gt_labels,labels,average=\"weighted\")\n",
    "    return acc,pre,rec,f1\n",
    "    \n",
    "    acc = 0\n",
    "    al = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==-1 or clts[i].tag == 1:\n",
    "            continue\n",
    "        al += 1\n",
    "        if labels[i] == clts[i].label:\n",
    "            acc += 1\n",
    "    return acc*1.0/(al*1.0)\n",
    "\n",
    "def aggregation(clts,mat,labels):\n",
    "    #ip,cert,url weight aggragation\n",
    "    def agg_weight(clt_c,clt_n,weight):\n",
    "        #ip agg\n",
    "        for ip in list(clt_n.ip_weight.keys()):\n",
    "            if ip not in list(clt_c.ip_weight.keys()):\n",
    "                clt_c.ip_weight[ip] = clt_n.ip_weight[ip] * weight\n",
    "            else:\n",
    "                clt_c.ip_weight[ip] += clt_c.ip_weight[ip] * clt_n.ip_weight[ip] * weight\n",
    "        #cert agg\n",
    "        for cert in list(clt_n.cert_weight.keys()):\n",
    "            if cert not in list(clt_c.cert_weight.keys()):\n",
    "                clt_c.cert_weight[cert] = clt_n.cert_weight[cert] * weight\n",
    "            else:\n",
    "                clt_c.cert_weight[cert] += clt_c.cert_weight[cert] * clt_n.cert_weight[cert] * weight\n",
    "                \n",
    "        #url agg\n",
    "        for url in list(clt_n.url_weight.keys()):\n",
    "            if url not in list(clt_c.url_weight.keys()):\n",
    "                clt_c.url_weight[url] = clt_n.url_weight[url] * weight\n",
    "            else:\n",
    "                clt_c.url_weight[url] += clt_c.url_weight[url] * clt_n.url_weight[url] * weight\n",
    "                \n",
    "        \n",
    "    \n",
    "    #aggregate the labeled nodes\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == -1:\n",
    "            continue\n",
    "        #aggragate the labeled nodes from same class\n",
    "        softmax_mat = []\n",
    "        for k in range(len(labels)):\n",
    "            if labels[k]!=-1 and labels[k]==labels[i]:\n",
    "                softmax_mat.append(mat[i][k])\n",
    "            else:\n",
    "                softmax_mat.append(0) \n",
    "        for j in range((len(labels))):\n",
    "            if i==j or labels[i] != labels[j]:\n",
    "                continue\n",
    "            #we aggregate the labled nodes from same class(so as to calculate the softmax)\n",
    "            agg_weight(clts[i],clts[j],softmax(softmax_mat)[j]) \n",
    "    #update the edge with the unlabeled nodes\n",
    "    adj_matrix = adj_matrix_gen(clts)\n",
    "    return adj_matrix\n",
    "            \n",
    "def label_update(clts,labels):\n",
    "    labels = []\n",
    "    for clt in clts:\n",
    "        if clt.tag == 0:\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(clt.label)\n",
    "    labels = np.array(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mat_init(IP_clusters):\n",
    "    adj_matrix = adj_matrix_gen(IP_clusters)\n",
    "    labels = []\n",
    "    for clt in IP_clusters:\n",
    "        if clt.tag == 0:\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(clt.label)\n",
    "    labels = np.array(labels)\n",
    "    return adj_matrix,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(mode, test_rate = 0):\n",
    "    #load traning data from net_A\n",
    "    with open(\"./dataset/InitTraffic.pkl\",'rb') as file:\n",
    "        dataT  = pickle.loads(file.read())\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(len(dataT.label)):\n",
    "        tmp = {}\n",
    "        tmp['IP'] = dataT.static_feature[i][0]\n",
    "        if len(dataT.cert_number[i]) is 0:\n",
    "            tmp['cert'] = 0\n",
    "        else:\n",
    "            tmp['cert'] = dataT.cert_number[i][0]\n",
    "        tmp['urls'] = [item for item in dataT.urls[i] if item != '0']\n",
    "        tmp['static_features'] = np.array([float(item) for item in dataT.static_feature[i][1:-2]])\n",
    "        tmp['seq'] = dataT.seq_matirx[i]\n",
    "        tmp['label'] = dataT.label[i]\n",
    "        tmp['time'] = (float(dataT.static_feature[i][-2]),float(dataT.static_feature[i][-1]))\n",
    "        tmp['image'] = dataT.image[i]\n",
    "        tmp['fn'] = dataT.fn[i]\n",
    "        tmp['tag'] = 1\n",
    "\n",
    "        data_list.append(tmp)\n",
    "    print(\"{} sessions loaded from training set.\".format(len(data_list)))\n",
    "\n",
    "    IP_clusters = []\n",
    "    used_sessions = []\n",
    "\n",
    "    #inital IP clusters\n",
    "    for i in range(len(data_list)):\n",
    "        session = data_list[i]\n",
    "        IP = session['IP']\n",
    "        if len(IP_clusters) == 0:\n",
    "            used_sessions.append(i)\n",
    "            clt = cert_cluster()\n",
    "            clt.sessions.append(session)\n",
    "            clt.update()\n",
    "            IP_clusters.append(clt)\n",
    "        else:\n",
    "            d = 0\n",
    "            for j in range(len(IP_clusters)):\n",
    "                if IP in IP_clusters[j].IPs:\n",
    "                    IP_clusters[j].sessions.append(session)\n",
    "                    IP_clusters[j].update()\n",
    "                    used_sessions.append(i)\n",
    "                    d = 1\n",
    "                    break\n",
    "\n",
    "            if d == 0:\n",
    "                used_sessions.append(i)\n",
    "                clt = cert_cluster()\n",
    "                clt.sessions.append(session)\n",
    "                clt.update()\n",
    "                IP_clusters.append(clt)\n",
    "\n",
    "    data_list = [data_list[i] for i in range(len(data_list)) if i not in used_sessions]\n",
    "    for item in IP_clusters:\n",
    "        item.time_cal()\n",
    "    if mode == 'cross':\n",
    "        print(\"{} clusters are initialized for training set.\".format(len(IP_clusters)))\n",
    "        \n",
    "    if mode == 'cross':\n",
    "        with open(\"./dataset/TestTraffic.pkl\",'rb') as file:\n",
    "            dataT  = pickle.loads(file.read())\n",
    "\n",
    "        for i in range(len(dataT.label)):\n",
    "            tmp = {}\n",
    "            tmp['IP'] = dataT.static_feature[i][0]\n",
    "            if len(dataT.cert_number[i]) is 0:\n",
    "                tmp['cert'] = 0\n",
    "            else:\n",
    "                tmp['cert'] = dataT.cert_number[i][0]\n",
    "            tmp['urls'] = [item for item in dataT.urls[i] if item != '0']\n",
    "            tmp['static_features'] = np.array([float(item) for item in dataT.static_feature[i][1:-2]])\n",
    "            tmp['seq'] = dataT.seq_matirx[i]\n",
    "            tmp['label'] = dataT.label[i]\n",
    "            tmp['time'] = (float(dataT.static_feature[i][-2]),float(dataT.static_feature[i][-1]))\n",
    "            tmp['image'] = dataT.image[i]\n",
    "            tmp['fn'] = dataT.fn[i]\n",
    "            tmp['tag'] = 0\n",
    "\n",
    "            data_list.append(tmp)\n",
    "        print(\"{} sessions loaded from testing set.\".format(len(data_list)))\n",
    "\n",
    "        IP_clusters_poor = []\n",
    "        used_sessions = []\n",
    "\n",
    "        #inital IP clusters\n",
    "        for i in range(len(data_list)):\n",
    "            session = data_list[i]\n",
    "            IP = session['IP']\n",
    "            if len(IP_clusters_poor) == 0:\n",
    "                used_sessions.append(i)\n",
    "                clt = cert_cluster()\n",
    "                clt.sessions.append(session)\n",
    "                clt.update()\n",
    "                IP_clusters_poor.append(clt)\n",
    "            else:\n",
    "                d = 0\n",
    "                for j in range(len(IP_clusters_poor)):\n",
    "                    if IP in IP_clusters_poor[j].IPs:\n",
    "                        IP_clusters_poor[j].sessions.append(session)\n",
    "                        IP_clusters_poor[j].update()\n",
    "                        used_sessions.append(i)\n",
    "                        d = 1\n",
    "                        break\n",
    "\n",
    "                if d == 0:\n",
    "                    used_sessions.append(i)\n",
    "                    clt = cert_cluster()\n",
    "                    clt.sessions.append(session)\n",
    "                    clt.update()\n",
    "                    IP_clusters_poor.append(clt)\n",
    "\n",
    "        data_list = [data_list[i] for i in range(len(data_list)) if i not in used_sessions]\n",
    "        for item in IP_clusters_poor:\n",
    "            item.time_cal()\n",
    "        IP_clusters.extend(IP_clusters_poor)\n",
    "        \n",
    "        print(\"{} clusters are initialized for testing set.\".format(len(IP_clusters_poor)))\n",
    "        print(\"{} nodes are included in the initialized graph.\".format(len(IP_clusters)))\n",
    "        return IP_clusters\n",
    "    else:\n",
    "        #construct testing set\n",
    "        label_idx_dict = {}\n",
    "        for i in range(len(IP_clusters)):\n",
    "            clt = IP_clusters[i]\n",
    "            if clt.label not in list(label_idx_dict.keys()):\n",
    "                label_idx_dict[clt.label] = [i]\n",
    "            else:\n",
    "                label_idx_dict[clt.label].append(i)\n",
    "        test_idx = []\n",
    "        for key in list(label_idx_dict.keys()):\n",
    "            idxs = np.arange(len(label_idx_dict[key]))\n",
    "            np.random.shuffle(idxs)\n",
    "            idxs = idxs[:int(idxs.shape[0]*test_rate)]\n",
    "            test_idx.extend(list(idxs))\n",
    "        for idx in test_idx:\n",
    "            IP_clusters[idx].tag = 0\n",
    "        print(\"{} clusters are initialized for training set.\".format(len(IP_clusters) - len(test_idx)))\n",
    "        print(\"{} clusters are initialized for testing set.\".format(len(test_idx)))\n",
    "        print(\"{} nodes are included in the initialized graph.\".format(len(IP_clusters)))\n",
    "        return IP_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 sessions loaded from training set.\n",
      "405 clusters are initialized for training set.\n",
      "1416 sessions loaded from testing set.\n",
      "267 clusters are initialized for testing set.\n",
      "672 nodes are included in the initialized graph.\n"
     ]
    }
   ],
   "source": [
    "#initialize training set and testing set ->IP_clusters\n",
    "IP_clusters = data_init(mode='cross', test_rate= 0.5)#ratio of the sessions in test set\n",
    "#adj_matrix and labels initialization\n",
    "adj_matrix,labels = label_mat_init(IP_clusters)\n",
    "#check out outer clusters\n",
    "outer_clt,max_indx_list = clt_analysis(IP_clusters,adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Confused nodes should be adjusted to the ground true labels.***\n",
      "137 no need for adjustment\n",
      "144: 5 -> 3\n",
      "172: 5 -> 3\n",
      "173: 5 -> 3\n",
      "338: 9 -> 7\n",
      "365 no need for adjustment\n",
      "396 no need for adjustment\n",
      "397: 9 -> 7\n",
      "398: 9 -> 7\n",
      "365 no need for adjustment\n",
      "\n",
      "Starting to propagate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\python3.6\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "d:\\software\\python3.6\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Acc: 0.9255952380952381 pre: 0.9255952380952381 rec: 0.9921193429661941 f1: 0.9577034544561026.\n",
      "Epoch : 1  Acc: 0.9285714285714286 pre: 0.9285714285714286 rec: 0.990609895273899 f1: 0.9585879501666213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\python3.6\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: overflow encountered in double_scalars\n",
      "d:\\software\\python3.6\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in double_scalars\n",
      "d:\\software\\python3.6\\lib\\site-packages\\ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2  Acc: 0.9419642857142857 pre: 0.9419642857142857 rec: 0.9911416337850975 f1: 0.965927434904187.\n",
      "Testing Acc: 0.9791666666666666 pre: 0.9791666666666666 rec: 0.9799944189075741 f1: 0.9792797833546572 after 3 epochs.\n"
     ]
    }
   ],
   "source": [
    "#update labels\n",
    "labels = label_update(IP_clusters,labels)\n",
    "#check out isolate clusters\n",
    "zero_idx = check_zero_label(adj_matrix,labels)\n",
    "zero_clts = [(i, IP_clusters[i]) for i in range(len(IP_clusters)) if i in zero_idx]\n",
    "adj_cand_clts = outer_clt + zero_clts\n",
    "#adjust iso clts to the gt classes\n",
    "print(\"*** Confused nodes should be adjusted to the ground true labels.***\")\n",
    "clts_adj = clt_adj(IP_clusters,adj_cand_clts)\n",
    "\n",
    "#start to propagate\n",
    "print()\n",
    "print(\"Starting to propagate.\")\n",
    "epoch = 3 # A small epoch can achieve satisfactory performance and prevent from overfitting\n",
    "for e in range(epoch):\n",
    "    # nodes aggregate info from neighbours and update the adjoin edges\n",
    "    adj_matrix = aggregation(clts_adj,adj_matrix,labels)\n",
    "    # update the labels\n",
    "    labels = label_update(clts_adj,labels)\n",
    "    # spread label info to the unlabeled neighbours\n",
    "    labels = spread(clts_adj,adj_matrix,labels)\n",
    "    # performing measurement in testing set\n",
    "    acc,pre,rec,f1 = acc_per_round(clts_adj,labels)\n",
    "    f1 = 2*pre*rec/(pre+rec)\n",
    "    print(\"Epoch : {}  Acc: {} pre: {} rec: {} f1: {}.\".format(e,acc,pre,rec,f1))\n",
    "# deal with the isolated nodes, aggregate by time info\n",
    "labels = enhc_iso(clts_adj,labels)\n",
    "f1 = 2*pre*rec/(pre+rec)\n",
    "acc,pre,rec,f1 = acc_per_round(clts_adj,labels)\n",
    "# acc after propagation\n",
    "print(\"Testing Acc: {} pre: {} rec: {} f1: {} after {} epochs.\".format(acc,pre,rec,f1,epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
